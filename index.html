<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="QiMeng-TensorOp: One-Line Prompt is Enough for High-Performance Tensor Operator Generation with Hardware Primitives">
  <meta property="keywords" content="Large Language Model, High Performace Code"/>
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>QiMeng-TensorOp: One-Line Prompt is Enough for High-Performance Tensor Operator Generation with Hardware Primitives</title>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/prism.min.css">
  <link rel="icon" href="./static/images/logo.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/prism.min.js"></script>
  <script src="./static/js/prism-cpp.min.js"></script>

  <style>
    .code-window {
      background-color: #282c34;
      border-radius: 8px;
      border: 1px solid #444;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
      margin: 20px 0;
      overflow: hidden;
    }
    
    .code-window-header {
      background: linear-gradient(90deg, #3e4651 0%, #2c313c 100%);
      padding: 12px 20px;
      border-bottom: 1px solid #444;
      display: flex;
      align-items: center;
      justify-content: space-between;
    }
    
    .code-window-title {
      color: #abb2bf;
      font-size: 14px;
      font-weight: 500;
      margin: 0;
    }
    
    .window-controls {
      display: flex;
      gap: 8px;
    }
    
    .window-control {
      width: 12px;
      height: 12px;
      border-radius: 50%;
    }
    
    .control-close { background-color: #ff5f56; }
    .control-minimize { background-color: #ffbd2e; }
    .control-maximize { background-color: #27ca3f; }
    
    .code-content {
      height: 400px;
      overflow-y: auto;
      overflow-x: auto;
      padding: 0;
      background-color: #282c34;
    }
    
    .code-content pre {
      margin: 0;
      padding: 20px;
      background-color: transparent;
      font-size: 14px;
      line-height: 1.5;
      color: #abb2bf;
      font-family: 'Fira Code', 'Monaco', 'Consolas', monospace;
    }
    
    .code-content::-webkit-scrollbar {
      width: 8px;
      height: 8px;
    }
    
    .code-content::-webkit-scrollbar-track {
      background: #21252b;
    }
    
    .code-content::-webkit-scrollbar-thumb {
      background: #4b5263;
      border-radius: 4px;
    }
    
    .code-content::-webkit-scrollbar-thumb:hover {
      background: #5c6370;
    }
  </style>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">QiMeng-TensorOp: One-Line Prompt is Enough for High-Performance Tensor Operator Generation with Hardware Primitives
            </h1>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                  <a>Xuzhi Zhang</a><sup>1,3</sup>,
              </span>
              <span class="author-block">
                  <a>Shaohui Peng</a><sup>1</sup>,
              </span>
              <span class="author-block">
                  <a>Qirui Zhou</a><sup>2,3</sup>,
              </span>
              <span class="author-block">
                  <a>Yuanbo Wen</a><sup>2</sup>,
              </span>
              <span class="author-block">
                  <a>Qi Guo</a><sup>2,3</sup>,
              </span>
              <span class="author-block">
                  <a>Ruizhi Chen</a><sup>1</sup>,
              </span>
              <span class="author-block">
                  <a>Xinguo Zhu</a><sup>1,3</sup>,
              </span>
              <span class="author-block">
                  <a>Weiqiang Xiong</a><sup>1,3</sup>,
              </span>
              <span class="author-block">
                  <a>Haixin Chen</a><sup>2,3</sup>,
              </span>
              <span class="author-block">
                  <a>Congying Ma</a><sup>1,4</sup>,
              </span>
              <span class="author-block">
                  <a>Ke Gao</a><sup>1</sup>,
              </span>
              <span class="author-block">
                  <a>Chen Zhao</a><sup>1</sup>,
              </span>
              <span class="author-block">
                  <a>Yanjun Wu</a><sup>1,3</sup>,
              </span>
              <span class="author-block">
                  <a>Yunji Chen</a><sup>2,3</sup>,
              </span>
              <span class="author-block">
                  and <a>Ling Li</a><sup>1,3*</sup>
              </span>
          </div>

          <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Institute of Software Chinese Academy of Sciences</span><br>
              <span class="author-block"><sup>2</sup>Institute of Computing Technology, Chinese Academy of Sciences</span><br>
              <span class="author-block"><sup>3</sup>University of Chinese Academy of Sciences</span><br>
              <span class="author-block"><sup>4</sup>Peking University</span>
          </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2505.06302" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code(coming soon)</span>
                  </a>
                </span>
                <!-- Tool Link. -->
                <span class="link-block">
                  <a href="http://1.94.237.163:7860/" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-screwdriver"></i>
                    </span>
                    <span>Tool(coming soon)</span>
                  </a>
                </span>
                <!-- Raw data Link-->
                <!-- <span class="link-block">
                  <a href="https://iprc-dip.github.io/Chip-Design-LLM-Zoo/"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-trophy"></i>
                    </span>
                    <span>Leaderboard</span>
                  </a>
                </span> -->
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

<!-- Paper abstract -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        
        <img src="./static/images/intro_compare_00.png" style="width: 400px; height: auto;">
        <div class="content has-text-justified">
          <p>
            Computation-intensive tensor operators constitute over 90% of the computations in Large Language Models (LLMs) and Deep Neural Networks. 
            Automatically and efficiently generating high-performance tensor operators with hardware primitives is crucial for diverse and 
            ever-evolving hardware architectures like RISC-V, ARM, and GPUs, as manually optimized implementation takes at least months 
            and lacks portability. LLMs excel at generating high-level language codes, but they struggle to fully comprehend hardware 
            characteristics and produce high-performance tensor operators.
          </p>
          <p>
            We introduce a tensor-operator auto-generation framework with a one-line user prompt (QiMeng-TensorOp), which enables LLMs 
            to automatically exploit hardware characteristics to generate tensor operators with hardware primitives, and tune parameters 
            for optimal performance across diverse hardware. Experimental results on various hardware platforms, SOTA LLMs, and typical 
            tensor operators demonstrate that QiMeng-TensorOp effectively unleashes the computing capability of various hardware platforms, 
            and automatically generates tensor operators of superior performance. Compared with vanilla LLMs, QiMeng-TensorOp achieves 
            up to 1291× performance improvement. Even compared with human experts, QiMeng-TensorOp could reach 251% of OpenBLAS on 
            RISC-V CPUs, and 124% of cuBLAS on NVIDIA GPUs. Additionally, QiMeng-TensorOp also significantly reduces development costs 
            by 200× compared with human experts.
</p>
        </div>
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3"></h2>
        <div class="content">
          <p>
            <thinking></thinking>

          We define a framework that enables LLMs to understand hardware architectures and automatically generate high-performance tensor operators. It optimizes code using hardware primitives and leverages Monte Carlo Tree Search (MCTS) to auto-tune parameters and instruction ordering, achieving performance beyond manual optimization.
          </p>
        </div>
        <img src="./static/images/overview_00.png" style="width: 100%; height: auto">
      </div>
    </div>

  </div>
  <!--/ Overview. -->
</div>
</section>
<!-- End paper abstract -->



<section class="section">
  <div class="container is-max-desktop">
    <!-- <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3"> Meta-prompt </h2>
          <p>
            We conduct our QiMeng-GEMM on some SOTA LLMs to evaluate the effectiveness. 
            We evaluate the GEMM code on various platforms including CPU(RISC-V Xuantie C910) and GPU(NVIDIA RTX 4070). 
            We test the performace of vanilla GPT-4o and claude-3.5-sonnet on many dimensions of GEMM.
          </p>
          <img src="./static/images/result1.png" style="display: block; margin: 0 auto; width: 60%; height: auto">
        </div>
      </div>
    </div> -->

    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3"> Main Results </h2>
          <p>
            We conduct comprehensive evaluations of QiMeng-TensorOp across multiple hardware platforms, state-of-the-art LLMs, and diverse tensor operators to validate its performance and generality. Our experiments demonstrate significant improvements over baseline methods and handcrafted optimization libraries.
          </p>
          <p>
            Platform Evaluation: QiMeng-TensorOp is extensively tested on a wide range of hardware architectures including RISC-V CPUs (C906, C908, C910, K1), ARM CPUs (A76, A72), and NVIDIA GPUs (RTX 4060, A100 with Tensor Cores).
          </p>
          <p>
            LLM Validation: The system's performance is validated using two leading LLMs - proprietary GPT-4o and open-source DeepSeek-V3, with additional testing on Claude 3.5 Sonnet and Llama-3.1-405B for ablation studies.
          </p>
          <p>
            Benchmark Coverage: Experiments include representative tensor operators (GEMM and Conv) with dimensions from popular models (Llama7b, Llama3 70b) and classical CNNs (ResNet-50, VGG-16, U-Net).
          </p>
          <p>
            The following is a partial result of the GEMM.
          </p>
          <img src="./static/images/result_00.png" style="display: block; margin: 0 auto; width: 60%; height: auto">
          <p>
        The following is the result of the convolution operator.
          </p>
          <img src="./static/images/result_11.png" style="display: block; margin: 0 auto; width: 50%; height: auto">
          <p>
          </p>
        </div>
      </div>
    </div>

  </div>

  <!-- Code Example Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Generated Code Example</h2>
          <p>
            This is a GEMM code generated for the C910 CPU, showing the C code sketch and assembly kernel code below: 
          </p>
          
          <div class="code-window" style="background-color: #ffffff !important; border: 1px solid #e0e0e0 !important;">
            <div class="code-window-header" style="background: linear-gradient(90deg, #f5f5f5 0%, #e8e8e8 100%) !important; border-bottom: 1px solid #e0e0e0 !important;">
              <h3 class="code-window-title" style="color: #333333 !important;">C code sketch</h3>
              <div class="window-controls">
                <div class="window-control control-close"></div>
                <div class="window-control control-minimize"></div>
                <div class="window-control control-maximize"></div>
              </div>
            </div>
            <div class="code-content">
              <pre><code class="language-cpp">
                #include "gemm.h"
                #include &lt;stdlib.h&gt;
                #include &lt;stdio.h&gt;

                #define GEMM_R 1024  // N dimension block size
                #define GEMM_Q 144   // K dimension block size  
                #define GEMM_P 48    // M dimension block size

                // Helper function to determine optimal block size
                static inline int choose_block_size(int remaining, int block_size) {
                    return (remaining < block_size) ? remaining : block_size;
                }

                void my_cblas_sgemm(const CBLAS_LAYOUT Layout, const CBLAS_TRANSPOSE TransA,
                                    const CBLAS_TRANSPOSE TransB, const int M, const int N,
                                    const int K, const float alpha, const float *A,
                                    const int lda, const float *B, const int ldb,
                                    const float beta, float *C, const int ldc) {
                    
                    // Handle layout and transpose parameters
                    // (assuming CblasRowMajor and CblasNoTrans for this implementation)
                    
                    // Dynamically allocate memory for packed matrices
                    float *sa = (float *)malloc(GEMM_P * GEMM_Q * sizeof(float));
                    float *sb = (float *)malloc(GEMM_Q * GEMM_R * sizeof(float));
                    
                    // Check for memory allocation failure
                    if (sa == NULL || sb == NULL) {
                        fprintf(stderr, "Error: Memory allocation failed for packed matrices\n");
                        if (sa) free(sa);
                        if (sb) free(sb);
                        return;
                    }
                    
                    // Beta scaling: Scale the output matrix C by beta
                    BETA_OPERATION(0, M, 0, N, beta, C, ldc);
                    
                    // Main computation loop following NKM cycle order for cache optimization
                    for (int js = 0; js < N; js += GEMM_R) {
                        int min_j = choose_block_size(N - js, GEMM_R);
                        
                        for (int ls = 0; ls < K; ls += GEMM_Q) {
                            int min_l = choose_block_size(K - ls, GEMM_Q);
                            
                            // Pack submatrix of B into buffer sb for better cache locality
                            OCOPY_OPERATION(min_l, min_j, B, ldb, ls, js, sb);
                            
                            for (int is = 0; is < M; is += GEMM_P) {
                                int min_i = choose_block_size(M - is, GEMM_P);
                                
                                // Pack submatrix of A into buffer sa
                                ICOPY_OPERATION(min_l, min_i, A, lda, ls, is, sa);
                                
                                // Perform matrix multiplication on packed submatrices
                                // This calls the optimized RISC-V vector kernel
                                KERNEL_OPERATION(min_i, min_j, min_l, alpha, sa, sb, C, ldc, is, js);
                            }
                        }
                    }
                    
                    // Clean up dynamically allocated memory
                    free(sa);
                    free(sb);
                }
              </code></pre>
            </div>
          </div>

          <div class="code-window" style="background-color: #ffffff !important; border: 1px solid #e0e0e0 !important;">
            <div class="code-window-header" style="background: linear-gradient(90deg, #f5f5f5 0%, #e8e8e8 100%) !important; border-bottom: 1px solid #e0e0e0 !important;">
              <h3 class="code-window-title" style="color: #333333 !important;">Assembly kernel code</h3>
              <div class="window-controls">
                <div class="window-control control-close"></div>
                <div class="window-control control-minimize"></div>
                <div class="window-control control-maximize"></div>
              </div>
            </div>
            <div class="code-content">
              <pre><code class="language-cpp">
                #include &lt;riscv_vector.h&gt;
                #define L2_16_4 \
                ...

                #define L2_8_4 \
                &quot;.L8x4_Init: \n\t&quot;\
                &quot;li         t0, 4 \n\t&quot;\
                &quot;vsetvli    t0, t0, e32, m1 \n\t&quot;\
                &quot;fmv.w.x    ft11, zero \n\t&quot;\
                &quot;vfmv.v.f   v12, ft11 \n\t&quot;\
                &quot;vfmv.v.f   v13, ft11 \n\t&quot;\
                &quot;vfmv.v.f   v14, ft11 \n\t&quot;\
                &quot;vfmv.v.f   v15, ft11 \n\t&quot;\
                &quot;vfmv.v.f   v16, ft11 \n\t&quot;\
                &quot;vfmv.v.f   v17, ft11 \n\t&quot;\
                &quot;vfmv.v.f   v18, ft11 \n\t&quot;\
                &quot;vfmv.v.f   v19, ft11 \n\t&quot;\
                &quot;vlw.v      v0,   (%[PA]) \n\t&quot;\
                &quot;flw        ft0,   0(%[PB]) \n\t&quot;\
                &quot;addi       %[PA], %[PA], 16 \n\t&quot;\
                &quot;vfmv.v.f   v4,   ft0 \n\t&quot;\
                &quot;flw        ft2,   8(%[PB]) \n\t&quot;\
                &quot;vlw.v      v1,   (%[PA]) \n\t&quot;\
                &quot;flw        ft1,   4(%[PB]) \n\t&quot;\
                &quot;addi       %[PA], %[PA], 16 \n\t&quot;\
                &quot;vfmv.v.f   v5,   ft1 \n\t&quot;\
                &quot;vfmv.v.f   v6,   ft2 \n\t&quot;\
                &quot;flw        ft3,   12(%[PB]) \n\t&quot;\
                &quot;vfmv.v.f   v7,   ft3 \n\t&quot;\
                &quot;addi       %[PB], %[PB], 16 \n\t&quot;\
                &quot;    mv     t0,   %[BK] \n\t&quot;\
                &quot;    srli   t1,   t0, 1 \n\t&quot;\
                &quot;    blez   t0,   .L8x4_End \n\t&quot;\
                &quot;.L8x4_Main: \n\t&quot;\
                &quot;    blez   t1,   .L8x4_Maintail \n\t&quot;\
                &quot;.L8x4_Mainloop: \n\t&quot;\
                &quot;vfmacc.vv  v12,  v0,    v4 \n\t&quot;\
                &quot;vfmacc.vv  v13,  v0,    v5 \n\t&quot;\
                &quot;vfmacc.vv  v14,  v0,    v6 \n\t&quot;\
                &quot;vfmacc.vv  v15,  v0,    v7 \n\t&quot;\
                &quot;vfmacc.vv  v16,  v1,    v4 \n\t&quot;\
                &quot;vfmacc.vv  v17,  v1,    v5 \n\t&quot;\
                &quot;vfmacc.vv  v18,  v1,    v6 \n\t&quot;\
                &quot;vfmacc.vv  v19,  v1,    v7 \n\t&quot;\
                &quot;vlw.v      v2,   (%[PA]) \n\t&quot;\
                &quot;flw        ft4,   0(%[PB]) \n\t&quot;\
                &quot;addi       %[PA], %[PA], 16 \n\t&quot;\
                &quot;vfmv.v.f   v8,   ft4 \n\t&quot;\
                &quot;vlw.v      v3,   (%[PA]) \n\t&quot;\
                &quot;flw        ft5,   4(%[PB]) \n\t&quot;\
                &quot;addi       %[PA], %[PA], 16 \n\t&quot;\
                ...

                int gemm_kernel(long bm,long bn,long bk,float alpha,float* ba,float* bb,float* C,long ldc)
                {
                  long i,j,k;
                  float *C0,*C1,*C2,*C3;
                  float *ptrba,*ptrbb;

                  for (j=0; j&lt;bn/4; j+=1){
                    C0 = C;
                    C1 = C0+ldc;
                    C2 = C1+ldc;
                    C3 = C2+ldc;

                    ptrba = ba;
                      for(i=0; i&lt;bm/16; i+=1) {
                        ptrbb = bb;
                        asm volatile(L2_16_4);
                      }
                      if(bm&amp;8) {
                        ptrbb = bb;
                        asm volatile(L2_8_4);
                      }
                      if(bm&amp;4) {
                        ptrbb = bb;
                        asm volatile(L2_4_4);
                      }
                      if(bm&amp;2) {
                        ptrbb = bb;
                        asm volatile(L2_2_4);
                      }
                      if(bm&amp;1) {
                        ptrbb = bb;
                        asm volatile(L2_1_4);
                      }
                      k = bk*4;
                    bb = bb+k;
                    i = ldc*4;
                    C = C+i;
                  }
                  if(bn&amp;2) {
                      C0 = C;
                    C1 = C0+ldc;

                    ptrba = ba;
                      for(i=0; i&lt;bm/16; i+=1) {
                        ptrbb = bb;
                        asm volatile(L2_16_2);
                      }
                      if(bm&amp;8) {
                        ptrbb = bb;
                        asm volatile(L2_8_2);
                      }
                      if(bm&amp;4) {
                        ptrbb = bb;
                        asm volatile(L2_4_2);
                      }
                      if(bm&amp;2) {
                        ptrbb = bb;
                        asm volatile(L2_2_2);
                      }
                      if(bm&amp;1) {
                        ptrbb = bb;
                        asm volatile(L2_1_2);
                      }
                      k = bk*2;
                    bb = bb+k;
                    i = ldc*2;
                    C = C+i;
                  }
                  if(bn&amp;1) {
                      C0 = C;
                    ptrba = ba;
                      for(i=0; i&lt;bm/16; i+=1) {
                        ptrbb = bb;
                        asm volatile(L2_16_1);
                      }
                      if(bm&amp;8) {
                        ptrbb = bb;
                        asm volatile(L2_8_1);
                      }
                      if(bm&amp;4) {
                        ptrbb = bb;
                        asm volatile(L2_4_1);
                      }
                      if(bm&amp;2) {
                        ptrbb = bb;
                        asm volatile(L2_2_1);
                      }
                      if(bm&amp;1) {
                        ptrbb = bb;
                        asm volatile(L2_1_1);
                      }
                      k = bk;
                    bb = bb+k;
                    C = C+ldc;
                  }
                  return 0 ;
                }
                </code></pre>


            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Code Example Section -->

<!--BibTex citation -->
    <div class="container content is-max-desktop">
      <h2 class="title is-3"> BibTex </h2>
        <pre>
      <code class="nohighlight" style="background-color: transparent; color:black; font-family: monospace;">
@misc{zhang2025qimengtensoropautomaticallygeneratinghighperformance,
      title={QiMeng-TensorOp: Automatically Generating High-Performance Tensor Operators with Hardware Primitives}, 
      author={Xuzhi Zhang and Shaohui Peng and Qirui Zhou and Yuanbo Wen and Qi Guo and Ruizhi Chen and Xinguo Zhu and Weiqiang Xiong and Haixin Chen and Congying Ma and Ke Gao and Chen Zhao and Yanjun Wu and Yunji Chen and Ling Li},
      year={2025},
      eprint={2505.06302},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2505.06302}, 
}
</code>
    </pre>
    </div>
</section>



<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
